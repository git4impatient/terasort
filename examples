# (c) copyright 2012 martin lurie - sample code not supported
# all rights reserved   may not be copied or published without permission

# 1 meg ROWS=10000
# 1 gig ROWS=10000000
# 100 gig ROWS=1000000000
# 500 gig ROWS=5000000000
# 1 tbyte ROWS=10000000000
# 1 meg ROWS=10000
# 1 meg ROWS=10000
# 1 meg ROWS=10000
export ROWS=1000
hadoop fs -rm -r terasort-input
hadoop fs -rm -r terasort-out
hadoop fs -rm -r teravalid-out
#hadoop jar /usr/lib/hadoop-0.20-mapreduce/hadoop-examples.jar teragen -Dmapred.map.tasks=16 -Dmapred.job.priority="VERY_LOW" $ROWS terasort-input
# ./lib/hadoop-0.20-mapreduce/hadoop-examples.jar
time hadoop jar /opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/hadoop-examples.jar teragen -Dmapred.map.tasks=16 -Dmapred.job.priority="VERY_LOW" $ROWS terasort-input
time hadoop jar /opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/hadoop-examples.jar terasort  -Dmapred.reduce.tasks=16  terasort-input terasort-out
time hadoop jar /opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/hadoop-examples.jar teravalidate  -Dmapred.job.priority="HIGH" terasort-out teravalid-out

exit


# from Vineet K.

# example f# The following will 1 TB file, 24 containers, each with 4GB =24*4=96GB Max Container memory

# cd /opt/clouderaâ€¦./lib/

#hadoop jar hadoop-mapreduce-examples.jar teragen -Dmapreduce.job.maps=24 -Dmapreduce.map.memory.mb=4096 -Dmapreduce.map.memory.mb=4096 10000000 /user/cloudera/tgen1TB
#hadoop jar hadoop-mapreduce-examples.jar terasort /user/cloudera/tgen1TB /user/cloudera/tshort
#hadoop jar hadoop-mapreduce-examples.jar teravalidate /user/cloudera/tshort /user/cloudera/tvalidate

# from Vineet K.


